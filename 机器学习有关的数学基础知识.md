# 机器学习有关的数学基础知识



# 概率论：




## 贝叶斯概率分布

当A,B都代表是一个事件的时候，条件概率的计算：p(AB)=P(A)P(A|B)。



贝叶斯概率分布由分子就是条件概率计算结果，分布就是全概率的就算结果。

更多看



## 离散型/连续型随机变量

* 随机变量X：为一映射,其自变量具有随机性，就是一个函数，注意：自变量是事件，因变量是事件发生的概率

* 若随机变量X的取值为有限个或可数,就称X离散,自变量-事件离散。



## 常见的离散型随机变量分布



### 0-1分布/贝努利分布

随机变量X的只可能取0，1 两个值，只有两个可能结果的试验，故称为**两点分布**有时也称为**贝努利分布**.

>可以理解为只有一次实验，两种可能的值的分布，注意其通用公式



### 二项分布

就是k重伯努利实验的分布中，p发生K次的概率，注意其通用公式

>注意，0-1分布/贝努利分布是二项分布的一种特殊情况，就是n=1的时候

>**x详见：课件-离散型分布**





### 泊松分布.

如果某事件以固定强度λ,随机且独立地出现，该事

件在单位时间内出现的次数（个数）可以看成是服从

泊松分布.

>**x详见：课件-离散型分布**



## 几何分布

在重复多次的贝努里试验中, 试验进行到某种结果出现第一次为止此时的试验总次数服从几何分布. 如：射击, 首次击中目标时射击的次数;

讲的例2.

>**x详见：课件-离散型分布**



### 分布函数

*　就是关于随机变量的函数，也就是关于x<某个值(在离散型表示的就是边界，在连续表示的就是某一个点)的函数

*　一般地，离散型随机变量的分布函数为阶梯函数，



>离散型和连续型分布函数的理解见**课件分布函数的意义**



## 概率密度和离散型随机变量

* 两个是相对应的，其性质是相对应的，详见**课件：随机变量，概率密度和连续型变量**

* 两个是一样的，但随机变量表示离散时的事件概率，概率密度表示在某个值的概率。



>**随机变量就是：事件到概率的映射，密度函数也一样，只不过是极限**

>**随机变量函数就是用随机变量做自变量**



>连续型结合直线上的例子，注意的是F(x)表示的是概率，面积总和为1，f（x）表示的是概率密度可以大于1，这个值大小满足积分为1，并大于0就可，可以用**课件：概率密度和连续型变量的例1**

>F(x)一定是一个连续函数



## 均匀分布

* 直观理解：x落到a，b等长即落入中的的任意子度等区间上是可能的.

*　概率计算就可以推导出是长度之比**其他详见课件:均匀分布和指数分布**



## 指数分布

* 概率密度函数是一个指数阶的

*　重要的性质，是无记忆性的**详见课件:均匀分布和指数分布，打电话的例子**，这个性质就是唯一的。

*　看是不是服从指数分布就可以通过是否有无记忆性来指出



## 高斯分布

*　一般的高斯分布可以转化（(x-u)/(方差)）为标准正太分布，然后再去查表算概率值



## 联合概率

* 条件概率和联合概率的区别，看例子**例5，离散型多元概率**





## 概率论中的独立同分布?请分别解释独立、同分布及独立同分布.

(1)独立就是每次抽样之间是没有关系的,不会相互影响

就像我抛色子每次抛到几就是几这就是独立的

但若我要两次抛的和大于8,其余的不算,那么第一次抛和第二次抛就不独立了,因为第二次抛的时候结果是和第一次相关的

(2)同分布的意思就是每次抽样,样本都服从同样的一个分布

抛色子每次得到任意点数的概率都是1/6,这就是同分布的

但若我第一次抛一个六面的色子,第二次抛一个正12面体的色子,就不再是同分布了

(3)独立同分布,也叫i,i,d,就是每次抽样之间独立而且同分布的意思

追问：

同分布是指服从同一分布函数么？是的。





## 联合分布

随机变量X和Y的联合分布函数是设(X,Y)是二维随机变量，对于任意实数x,y，二元函数：F(x,y) = P{(X<=x) 交 (Y<=y)} => P(X<=x, Y<=y)称为二维随机变量(X,Y)的分布函数。



## 二元高斯分布

*　关于二元的条件和边际分布，请查看慕课

*　注意边际分布和条件分布也是一个一元的高斯分布。



## 期望

* 连续型的期望可以类比离散型的期望，不过就是一个是求和，一个是积分

* 



## 极大似然估计

* 就是先给出一定的样本结果，通过结果来极大的估计参数值，使得得到这样结果的可能性最大**具体看课件：极大似然估计**

* 如果是离散型的就是随机事件的概率，如果是连续型的可能就是一个参数**具体看课件：极大似然估计**

[混合概率模型](http://wenku.baidu.com/link?url=Bh9Zhx3xPnT_yLtWfe6GHgUugl3W78iF2qVBvoo8q1BBhcJzsrdmYWqJo5wgfKsBjSY_7QqsagHx2vwZnMKyPJl3dl0xY_5Wue-XhyjMQT3)



### 协方差矩阵

[协方差,方差](http://www.cnblogs.com/cvlabs/archive/2010/03/26/1696978.html)

[协方差矩阵](http://www.zipperary.com/2014/01/12/covariance/)

[协方差矩阵-pac](http://blog.163.com/baolong_zhu/blog/static/196311091201421185531966/)

* 理解协方差矩阵的关键就在于牢记它计算的是不同维度之间的协方差，而不是不同样本之间，拿到一个样本矩阵，我们最先要明确的就是一行是一个样本还是一个维度，心中明确这个整个计算过程就会顺流而下，这么一来就不会迷茫了

[协方差矩阵的几何意义](http://www.cnblogs.com/nsnow/p/4758202.html)



1. 对角线元素(i,i)为数据第 i 维的方差。

2. 非对角线元素(i,j)为第 i 维和第 j 维的协方差。

3. 协方差矩阵是对称阵。



# 线性代数

### 正定矩阵

* 设M是n阶方阵，如果对任何非零向量z，都有zTMz> 0，其中zT 表示z的转置，就称M正定矩阵。



###  特征向量和特征值
[特征向量和特征值](https://www.zhihu.com/question/21874816)

矩阵乘法对应了一个变换，是把任意一个向量变成另一个方向或长度都大多不同的新向量。在这个变换的过程中，原向量主要发生旋转、伸缩的变化。如果矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。

实际上，上述的一段话既讲了矩阵变换特征值及特征向量的几何意义（图形变换）也讲了其物理含义。物理的含义就是运动的图景：特征向量在一个矩阵的作用下作伸缩运动，伸缩的幅度由特征值确定。特征值大于1，所有属于此特征值的特征向量身形暴长；特征值大于0小于1，特征向量身形猛缩；特征值小于0，特征向量缩过了界，反方向到0点那边去了。
    注意：常有教科书说特征向量是在矩阵变换下不改变方向的向量，实际上当特征值小于零时，矩阵就会把特征向量完全反方向改变，当然特征向量还是特征向量。我赞同特征向量不改变方向的说法：特征向量永远不改变方向，改变的只是特征值（方向反转特征值为负值了）。
特征向量是线性不变量

## 奇异值和特征值
奇异值分解的含义是，把一个矩阵A看成线性变换（当然也可以看成是数据矩阵或者样本矩阵），那么这个线性变换的作用效果是这样的，我们可以在原空间找到一组标准正交基V，同时可以在像空间找到一组标准正交基U，我们知道，看一个矩阵的作用效果只要看它在一组基上的作用效果即可，在内积空间上，我们更希望看到它在一组标准正交基上的作用效果。而矩阵A在标准正交基V上的作用效果恰好可以表示为在U的对应方向上只进行纯粹的伸缩！这就大大简化了我们对矩阵作用的认识，因为我们知道，我们面前不管是多么复杂的矩阵，它在某组标准正交基上的作用就是在另外一组标准正交基上进行伸缩而已。

特征分解也是这样的，也可以简化我们对矩阵的认识。对于可对角化的矩阵，该线性变换的作用就是将某些方向（特征向量方向）在该方向上做伸缩。

有了上述认识，当我们要看该矩阵对任一向量x的作用效果的时候，在特征分解的视角下，我们可以把x往特征向量方向上分解，然后每个方向上做伸缩，最后再把结果加起来即可；在奇异值分解的视角下，我们可以把x往V方向上分解，然后将各个分量分别对应到U方向上做伸缩，最后把各个分量上的结果加起来即可。

作者：lao king
链接：https://www.zhihu.com/question/22237507/answer/28007137
来源：知乎
著作权归作者所有，转载请联系作者获得授权。
* 不是所有的矩阵都能对角化（对称矩阵总是可以），而所有矩阵总是可以做奇异值分解的。那么多类型的矩阵，我们居然总是可以从一个统一且简单的视角去看它，我们就会感叹奇异值分解是多么奇妙了！

[奇异值的意义](http://blog.csdn.net/redline2005/article/details/24100293)

[奇异值的意义](https://www.zhihu.com/question/22237507/answer/28007137)

如果A是实矩阵,那么
1. AA^T是实对称半正定矩阵
2. rank(A)=rank(AA^T)
3. ||A||_2^2 = ||AA^T||_2
4. AA^T的特征值是A的奇异值的平方
只需要会证明4就行了,1,2,3都是推论.
















